{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from einops import repeat, rearrange\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgs_to_ndarray(imgs):\n",
    "    # Code from https://stackoverflow.com/a/62781370\n",
    "    magic_number = int.from_bytes(imgs.read(4), 'big')\n",
    "    image_count = int.from_bytes(imgs.read(4), 'big')\n",
    "    row_count = int.from_bytes(imgs.read(4), 'big')\n",
    "    column_count = int.from_bytes(imgs.read(4), 'big')\n",
    "    image_data = imgs.read()\n",
    "    images = np.frombuffer(image_data, dtype=np.uint8).reshape((image_count, row_count, column_count))\n",
    "    return images\n",
    "\n",
    "\n",
    "def labels_to_ndarray(labels):\n",
    "    # Code from https://stackoverflow.com/a/62781370\n",
    "    magic_number = int.from_bytes(labels.read(4), 'big')\n",
    "    label_count = int.from_bytes(labels.read(4), 'big')\n",
    "    label_data = labels.read()\n",
    "    labels = np.frombuffer(label_data, dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def read_mnist():\n",
    "    imgs = gzip.open(\"../datasets/mnist/train-images-idx3-ubyte.gz\", \"r\")\n",
    "    labels = gzip.open(\"../datasets/mnist/train-labels-idx1-ubyte.gz\", \"r\")\n",
    "    imgs = imgs_to_ndarray(imgs)\n",
    "    labels = labels_to_ndarray(labels)\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "def select_data(imgs, labels, digits, n):\n",
    "    \"\"\"Selects first `n` images of each digit in `digits`.\"\"\"\n",
    "    selected_imgs = []\n",
    "    for digit in digits:\n",
    "        mask = labels == digit\n",
    "        selected_imgs.extend(imgs[mask][:n])\n",
    "    return np.stack(selected_imgs)\n",
    "\n",
    "\n",
    "def subsample_min_dist(t, n, min_dist):\n",
    "    \"\"\"Subsamples `n` time points from `t` while keeping the smallest distance\n",
    "    between the time points at least `min_dist`.\n",
    "    \"\"\"\n",
    "    assert n <= len(t), \"Too large `n`.\"\n",
    "    assert min_dist <= (t.max() - t.min()) / (n - 1), \"Too large `min_dist`.\"\n",
    "    inds = [0, len(t)-1]\n",
    "    for i in range(n-2):\n",
    "        c, c_max = 0, 1e4\n",
    "        while True:\n",
    "            ind_i = np.random.choice(len(t), size=1)\n",
    "            dists = np.abs(t[inds] - t[ind_i])\n",
    "            if all(dists >= min_dist):\n",
    "                inds.append(ind_i.item())\n",
    "                break\n",
    "            if c > c_max:\n",
    "                raise RuntimeError(\"Failed to subsample the time grid. Use smalled `n` or `min_dist`.\")\n",
    "            c += 1\n",
    "    return t[sorted(inds)]\n",
    "\n",
    "\n",
    "def generate_irregular_time_grid(T, M, min_dist, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    t = np.linspace(0, T, 100*M)\n",
    "    t = subsample_min_dist(t, M, min_dist)\n",
    "    return t\n",
    "\n",
    "\n",
    "def pickle_data(data_dict: dict[str, list], path: str =\"./\") -> None:\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for name, data in data_dict.items():\n",
    "        with open(path+name+\".pkl\", \"wb\") as f:\n",
    "            pickle.dump(data, f, protocol=4)\n",
    "\n",
    "\n",
    "class MNISTDrawer():\n",
    "    def __init__(self, img, pad_size=2) -> None:\n",
    "        self.img = img\n",
    "        self.img_width = img.shape[0]\n",
    "        self.img_height = img.shape[1]\n",
    "        self.pad_size = pad_size\n",
    "\n",
    "    def get_image(self, angle):\n",
    "        image = Image.fromarray(self.img)\n",
    "        image = image.rotate(angle, resample=Image.BICUBIC)\n",
    "        image = np.pad(np.array(image), (self.pad_size, self.pad_size))\n",
    "        return image\n",
    "\n",
    "\n",
    "def generate_data(img, T, M, regular, seed=None):\n",
    "    pad_size = 2\n",
    "    mnist_drawer = MNISTDrawer(img, pad_size)\n",
    "\n",
    "    if regular is True:\n",
    "        t = np.linspace(0, T, M)\n",
    "    else:\n",
    "        t = generate_irregular_time_grid(T, M, T/(4*(M-1)), seed=seed)\n",
    "        # t = generate_irregular_time_grid(T, M, dt=T/(M-1), seed=seed)\n",
    "\n",
    "    y = np.empty((1, M, 1, (img.shape[0]+2*pad_size)**2), dtype=np.uint8)\n",
    "    y_raw = np.empty((1, M, 1, 2), dtype=np.float32)\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    for i in range(1):\n",
    "        theta_0 = np.random.rand() * (2 * np.pi)\n",
    "        omega = np.pi * (1 + np.random.rand())\n",
    "\n",
    "        theta = theta_0 + omega * t\n",
    "\n",
    "        y_raw[i, :, 0, 0] = theta / np.pi * 180  # radians to angles\n",
    "        y_raw[i, :, 0, 1] = omega / np.pi * 180  # radians to angles\n",
    "        y_raw[i, :, 0, 0] %= 360\n",
    "\n",
    "        # Generate images from angles.\n",
    "        mnist_imgs = np.stack([mnist_drawer.get_image(theta_i) for theta_i in y_raw[i, :, 0, 0]]).reshape(M, -1)\n",
    "        y[i, :, 0, :] = mnist_imgs\n",
    "\n",
    "    return t, y, y_raw  # Shapes - y: (1, M, 1, 32**2), y_raw: (1, M, 1, 2), t: (M, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Download train-images-idx3-ubyte.gz and train-labels-idx1-ubyte.gz from http://yann.lecun.com/exdb/mnist/ and save it to .../datasets/mnist/ first.\n",
    "\n",
    "SEED = 1545\n",
    "\n",
    "S = 5000  # number of simulations (5000)\n",
    "M = 51  # number of time points (51)\n",
    "T = 2.0  # terminal time (1.0)\n",
    "regular = True  # regular/irregular grid flag\n",
    "\n",
    "y = []  # data (image)\n",
    "y_raw = []  # raw data (angle and angular velocity)\n",
    "t = []  # time grids\n",
    "\n",
    "imgs, labels = read_mnist()\n",
    "imgs = select_data(imgs, labels, digits=[3], n=S)\n",
    "\n",
    "# np.random.seed(SEED)\n",
    "for i in tqdm(range(S), total=S):\n",
    "    t_i, y_i, y_raw_i = generate_data(imgs[i], T, M, seed=SEED+i, regular=regular)\n",
    "    t.append(t_i.reshape(-1, 1))\n",
    "    y.append(y_i[0])\n",
    "    y_raw.append(y_raw_i[0])\n",
    "\n",
    "\n",
    "a, b = int(0.8*S), int(0.9*S)\n",
    "t_train, t_val, t_test = t[0:a], t[a:b], t[b:]\n",
    "y_train, y_val, y_test = y[0:a], y[a:b], y[b:]\n",
    "\n",
    "if regular:\n",
    "    pickle_data({\"t\": t_train, \"y\": y_train}, path=f\"../datasets/rmnist_unif/train/\")\n",
    "    pickle_data({\"t\": t_val, \"y\": y_val}, path=f\"../datasets/rmnist_unif/val/\")\n",
    "    pickle_data({\"t\": t_test, \"y\": y_test}, path=f\"../datasets/rmnist_unif/test/\")\n",
    "else:\n",
    "    pickle_data({\"t\": t_train, \"y\": y_train}, path=f\"../datasets/rmnist/train/\")\n",
    "    pickle_data({\"t\": t_val, \"y\": y_val}, path=f\"../datasets/rmnist/val/\")\n",
    "    pickle_data({\"t\": t_test, \"y\": y_test}, path=f\"../datasets/rmnist/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Minimum number of time points: {np.min([ti.shape[0] for ti in t])}\\n\"\n",
    "    f\"Maximum number of time points: {np.max([ti.shape[0] for ti in t])}\\n\\n\"\n",
    "\n",
    "    f\"Minimum time: {np.min([ti[0, 0] for ti in t])}\\n\"\n",
    "    f\"Maximum time: {np.max([ti[-1, 0] for ti in t])}\\n\\n\"\n",
    "\n",
    "    f\"Minimum temporal distance: {np.min([np.diff(ti.ravel()) for ti in t]):.3f}\\n\"\n",
    "    f\"Maximum temporal distance: {np.max([np.diff(ti.ravel()) for ti in t]):.3f}\\n\\n\"\n",
    "\n",
    "    f\"Minimum angle: {np.min([yi[:, 0, 0].min() for yi in y_raw]):.1f}\\n\"\n",
    "    f\"Maximum angle: {np.max([yi[:, 0, 0].max() for yi in y_raw]):.1f}\\n\\n\"\n",
    "\n",
    "    f\"Minimum angular velocity: {np.min([yi[:, 0, 1].min() for yi in y_raw]):.1f}\\n\"\n",
    "    f\"Maximum angular velocity: {np.max([yi[:, 0, 1].max() for yi in y_raw]):.1f}\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.concatenate([yi[:, 0, 0] for yi in y_raw])\n",
    "angular_velocities = np.concatenate([yi[:, 0, 1] for yi in y_raw])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].grid(False)\n",
    "\n",
    "ax[0].hist(angles, bins=30)\n",
    "ax[0].set_title(\"Angles\")\n",
    "ax[0].set_xlabel(\"Angle [deg]\")\n",
    "\n",
    "ax[1].hist(angular_velocities, bins=30)\n",
    "ax[1].set_title(\"Angular velocities\")\n",
    "ax[1].set_xlabel(\"Angular velocity [deg/sec]\")\n",
    "\n",
    "ax[2].hist2d(angles, angular_velocities, bins=30)\n",
    "ax[2].set_title(\"Angle vs ang. velocities\")\n",
    "ax[2].set_xlabel(\"Angle [deg]\")\n",
    "ax[2].set_ylabel(\"Angular velocity [deg/sec]\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inf = 0.15 * T\n",
    "t_inf_size = np.array([sum(ti.ravel() <= t_inf) for ti in t])\n",
    "\n",
    "print(\n",
    "    f\"Minimum number of time points before {t_inf:.3f} sec.: {np.min(t_inf_size)}\\n\"\n",
    "    f\"Minimum number of time points before {t_inf:.3f} sec.: {np.max(t_inf_size)}\"\n",
    ")\n",
    "\n",
    "plt.hist(t_inf_size, bins=20)\n",
    "plt.title(f\"Number of observations before {t_inf:.3f} sec.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 8\n",
    "inds_for_size = np.argwhere(t_inf_size == size).ravel()\n",
    "\n",
    "for i in range(min(5, len(inds_for_size))):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 2))\n",
    "    ax.vlines(t[inds_for_size[i]].ravel(), -0.1, 0.1)\n",
    "    ax.vlines(t_inf, -0.1, 0.1, color=\"r\", linestyle=\"--\")\n",
    "    ax.set_ylim(-0.2, 0.2)\n",
    "    ax.set_title(f\"Time grid with {size} observations before {t_inf:.1f} sec. Index: {inds_for_size[i]}.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ind = 3\n",
    "\n",
    "plt.plot(t[sim_ind].ravel(), y_raw[sim_ind][:, 0, 0], \"X-\", label=r\"$\\theta$\")\n",
    "plt.plot(t[sim_ind].ravel(), y_raw[sim_ind][:, 0, 1], \"X-\", label=r\"$\\dot{\\theta}$\")\n",
    "plt.title(f\"Angle and angular velocity for simulation {sim_ind}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "n, skip = 10, 5\n",
    "fig, ax = plt.subplots(1, n, figsize=(n*5, 5))\n",
    "for i in range(n):\n",
    "    ax[i].grid(False)\n",
    "    ax[i].imshow(y[sim_ind][i*skip, :, :].astype(np.float32).reshape(32, 32))\n",
    "fig.suptitle(f\"First {n*skip}:{skip} observations from sim. {sim_ind}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input = []\n",
    "for yi in y:\n",
    "    pca_input.extend(yi[:, 0, :])\n",
    "pca_input = np.array(pca_input)\n",
    "\n",
    "pca = PCA(n_components=32, whiten=False)\n",
    "pca_output = pca.fit_transform(pca_input)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "ax[0].plot(pca.explained_variance_ratio_)\n",
    "ax[0].set_title(\"Explained variance ratio\")\n",
    "ax[0].set_xlabel(\"PCA components\")\n",
    "\n",
    "ax[1].plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "ax[1].set_title(\"Cumulative explained variance ratio\")\n",
    "ax[1].set_xlabel(\"PCA components\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d0a476cee8751458044a46780fa2da455e0fcd98e0a3ebdd69f30a55181eb17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
